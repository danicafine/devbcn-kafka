## Building Streaming Data Pipelines Workshop Prerequisites 

This workshop assumes little to no prior knowledge of Kafka, but we recommend you have some working knowledge of programming languages as we’ll be using Python for the course. We’ll build up a foundational understanding of Kafka and help you to build (and customize) your own end-to-end streaming data pipeline by the end of the workshop.

In order to make sure you’re fully prepared to get the most value out of our workshop, we have a few things to you to do ***prior to the workshop***:
- We’ll be using Confluent Cloud throughout the workshop; [create a free Confluent Cloud account](https://confluent.cloud/signup?&utm_medium=slide&utm_source=conference&utm_term=dfine-devx) ahead of time.
- Install Python 3.6+ on your machine.
- Install [Apache Kafka](https://docs.confluent.io/kafka-clients/python/current/overview.html#ak-python?utm_source=conference&utm_medium=slide&utm_term=dfine-devx) on your machine. Note that M1s require a manual install of librdkafka; this [blog post](https://dev.to/cerchie/installing-node-rdkafka-on-m1-for-use-with-sasl-3i47) contains instructions that will help. 
- Remember to bring your own laptop to use during the workshop. We have a preference for machines with a MacOS or Linux operating system installed; Linux on Windows can be accommodated. ***You must have a personal machine to use to attend the workshop.***